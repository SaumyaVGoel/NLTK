{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed2ca824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\saumya vikas goel\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: tqdm in c:\\users\\saumya vikas goel\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: click in c:\\users\\saumya vikas goel\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\saumya vikas goel\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\saumya vikas goel\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\saumya vikas goel\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0af53c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b42f563",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package bcp47 to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to C:\\Users\\Saumya\n",
      "[nltk_data]    |     Vikas Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to C:\\Users\\Saumya\n",
      "[nltk_data]    |     Vikas Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to C:\\Users\\Saumya\n",
      "[nltk_data]    |     Vikas Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to C:\\Users\\Saumya\n",
      "[nltk_data]    |     Vikas Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to C:\\Users\\Saumya\n",
      "[nltk_data]    |     Vikas Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to C:\\Users\\Saumya\n",
      "[nltk_data]    |     Vikas Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to C:\\Users\\Saumya\n",
      "[nltk_data]    |     Vikas Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package extended_omw to C:\\Users\\Saumya\n",
      "[nltk_data]    |     Vikas Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to C:\\Users\\Saumya\n",
      "[nltk_data]    |     Vikas Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\framenet_v15.zip.\n",
      "[nltk_data]    | Downloading package framenet_v17 to C:\\Users\\Saumya\n",
      "[nltk_data]    |     Vikas Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\framenet_v17.zip.\n",
      "[nltk_data]    | Downloading package gazetteers to C:\\Users\\Saumya\n",
      "[nltk_data]    |     Vikas Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\gazetteers.zip.\n",
      "[nltk_data]    | Downloading package genesis to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\genesis.zip.\n",
      "[nltk_data]    | Downloading package gutenberg to C:\\Users\\Saumya\n",
      "[nltk_data]    |     Vikas Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\gutenberg.zip.\n",
      "[nltk_data]    | Downloading package ieer to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\ieer.zip.\n",
      "[nltk_data]    | Downloading package inaugural to C:\\Users\\Saumya\n",
      "[nltk_data]    |     Vikas Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\inaugural.zip.\n",
      "[nltk_data]    | Downloading package indian to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\indian.zip.\n",
      "[nltk_data]    | Downloading package jeita to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package kimmo to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\kimmo.zip.\n",
      "[nltk_data]    | Downloading package knbc to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package large_grammars to C:\\Users\\Saumya\n",
      "[nltk_data]    |     Vikas Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars\\large_grammars.zip.\n",
      "[nltk_data]    | Downloading package lin_thesaurus to C:\\Users\\Saumya\n",
      "[nltk_data]    |     Vikas Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\lin_thesaurus.zip.\n",
      "[nltk_data]    | Downloading package mac_morpho to C:\\Users\\Saumya\n",
      "[nltk_data]    |     Vikas Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\mac_morpho.zip.\n",
      "[nltk_data]    | Downloading package machado to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package masc_tagged to C:\\Users\\Saumya\n",
      "[nltk_data]    |     Vikas Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping chunkers\\maxent_ne_chunker.zip.\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers\\maxent_treebank_pos_tagger.zip.\n",
      "[nltk_data]    | Downloading package moses_sample to C:\\Users\\Saumya\n",
      "[nltk_data]    |     Vikas Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping models\\moses_sample.zip.\n",
      "[nltk_data]    | Downloading package movie_reviews to C:\\Users\\Saumya\n",
      "[nltk_data]    |     Vikas Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\movie_reviews.zip.\n",
      "[nltk_data]    | Downloading package mte_teip5 to C:\\Users\\Saumya\n",
      "[nltk_data]    |     Vikas Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\mte_teip5.zip.\n",
      "[nltk_data]    | Downloading package mwa_ppdb to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping misc\\mwa_ppdb.zip.\n",
      "[nltk_data]    | Downloading package names to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\names.zip.\n",
      "[nltk_data]    | Downloading package nombank.1.0 to C:\\Users\\Saumya\n",
      "[nltk_data]    |     Vikas Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\nonbreaking_prefixes.zip.\n",
      "[nltk_data]    | Downloading package nps_chat to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\nps_chat.zip.\n",
      "[nltk_data]    | Downloading package omw to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package omw-1.4 to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\opinion_lexicon.zip.\n",
      "[nltk_data]    | Downloading package panlex_swadesh to C:\\Users\\Saumya\n",
      "[nltk_data]    |     Vikas Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package paradigms to C:\\Users\\Saumya\n",
      "[nltk_data]    |     Vikas Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\paradigms.zip.\n",
      "[nltk_data]    | Downloading package pe08 to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\pe08.zip.\n",
      "[nltk_data]    | Downloading package perluniprops to C:\\Users\\Saumya\n",
      "[nltk_data]    |     Vikas Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping misc\\perluniprops.zip.\n",
      "[nltk_data]    | Downloading package pil to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\pil.zip.\n",
      "[nltk_data]    | Downloading package pl196x to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\pl196x.zip.\n",
      "[nltk_data]    | Downloading package porter_test to C:\\Users\\Saumya\n",
      "[nltk_data]    |     Vikas Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers\\porter_test.zip.\n",
      "[nltk_data]    | Downloading package ppattach to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\ppattach.zip.\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\problem_reports.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\product_reviews_1.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\product_reviews_2.zip.\n",
      "[nltk_data]    | Downloading package propbank to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package pros_cons to C:\\Users\\Saumya\n",
      "[nltk_data]    |     Vikas Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\pros_cons.zip.\n",
      "[nltk_data]    | Downloading package ptb to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\ptb.zip.\n",
      "[nltk_data]    | Downloading package punkt to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data]    | Downloading package qc to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\qc.zip.\n",
      "[nltk_data]    | Downloading package reuters to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package rslp to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers\\rslp.zip.\n",
      "[nltk_data]    | Downloading package rte to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\rte.zip.\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars\\sample_grammars.zip.\n",
      "[nltk_data]    | Downloading package semcor to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package senseval to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\senseval.zip.\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\sentence_polarity.zip.\n",
      "[nltk_data]    | Downloading package sentiwordnet to C:\\Users\\Saumya\n",
      "[nltk_data]    |     Vikas Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\sentiwordnet.zip.\n",
      "[nltk_data]    | Downloading package shakespeare to C:\\Users\\Saumya\n",
      "[nltk_data]    |     Vikas Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\shakespeare.zip.\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\sinica_treebank.zip.\n",
      "[nltk_data]    | Downloading package smultron to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\smultron.zip.\n",
      "[nltk_data]    | Downloading package snowball_data to C:\\Users\\Saumya\n",
      "[nltk_data]    |     Vikas Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars\\spanish_grammars.zip.\n",
      "[nltk_data]    | Downloading package state_union to C:\\Users\\Saumya\n",
      "[nltk_data]    |     Vikas Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\state_union.zip.\n",
      "[nltk_data]    | Downloading package stopwords to C:\\Users\\Saumya\n",
      "[nltk_data]    |     Vikas Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data]    | Downloading package subjectivity to C:\\Users\\Saumya\n",
      "[nltk_data]    |     Vikas Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\subjectivity.zip.\n",
      "[nltk_data]    | Downloading package swadesh to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\swadesh.zip.\n",
      "[nltk_data]    | Downloading package switchboard to C:\\Users\\Saumya\n",
      "[nltk_data]    |     Vikas Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\switchboard.zip.\n",
      "[nltk_data]    | Downloading package tagsets to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping help\\tagsets.zip.\n",
      "[nltk_data]    | Downloading package timit to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\timit.zip.\n",
      "[nltk_data]    | Downloading package toolbox to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\toolbox.zip.\n",
      "[nltk_data]    | Downloading package treebank to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\treebank.zip.\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\twitter_samples.zip.\n",
      "[nltk_data]    | Downloading package udhr to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\udhr.zip.\n",
      "[nltk_data]    | Downloading package udhr2 to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\udhr2.zip.\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\unicode_samples.zip.\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers\\universal_tagset.zip.\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package vader_lexicon to C:\\Users\\Saumya\n",
      "[nltk_data]    |     Vikas Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package verbnet to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\verbnet.zip.\n",
      "[nltk_data]    | Downloading package verbnet3 to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\verbnet3.zip.\n",
      "[nltk_data]    | Downloading package webtext to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\webtext.zip.\n",
      "[nltk_data]    | Downloading package wmt15_eval to C:\\Users\\Saumya\n",
      "[nltk_data]    |     Vikas Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping models\\wmt15_eval.zip.\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping models\\word2vec_sample.zip.\n",
      "[nltk_data]    | Downloading package wordnet to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet2021 to C:\\Users\\Saumya\n",
      "[nltk_data]    |     Vikas Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet31 to C:\\Users\\Saumya\n",
      "[nltk_data]    |     Vikas Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet_ic to C:\\Users\\Saumya\n",
      "[nltk_data]    |     Vikas Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\wordnet_ic.zip.\n",
      "[nltk_data]    | Downloading package words to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\words.zip.\n",
      "[nltk_data]    | Downloading package ycoe to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]    |     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\ycoe.zip.\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6c7ed15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "from nltk.corpus import brown\n",
    "import numpy as np\n",
    "nltk.download('brown')\n",
    "from nltk.corpus import brown\n",
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a015cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of words is: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1161192"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Length of words is: \")\n",
    "len(brown.words()) #tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91acfdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words:\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "number_of_words = 0\n",
    "with open('nlp.txt','r') as file:\n",
    "\tdata = file.read()\n",
    "\tlines = data.split()\n",
    "\tnumber_of_words += len(lines)\n",
    "print(\"Total number of words:\")\n",
    "print(number_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b7b33aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jane Austenâ€™s Pride and Prejudice is an 18th-century novel of manners set in rural England and portraying the relationships between the four daughters of the Bennet family and their neighbors. While accurately and vividly depicting the manners and social norms of that time, the novel also provides sharp observations on the themes of love, marriage, class, money, education, and social prestige. In this paper, the four main themes of Pride and Prejudice are analyzed. Marriage is the main topic around which the plot revolves. The author illustrates the conflict between marrying for money, which was the typical idea at the time, and marrying for love. In either case, the economic and social differences were obstacles which made it hard for young women from poor families to break out of their social circle. Each personâ€™s position in society was determined by their class, and the relations between families also centered around differences in wealth and status. The gender differences also played an important role, as women were considered inferior to men and were practically unable to choose partners. Austen both criticizes and examines the social life of 18th-century England, advocating for marrying for love as one of the essential female rights.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(\"nlp.txt\", 'r', errors = 'ignore')\n",
    "x = f.read()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5e8ed49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({' ': 199, 'e': 136, 'a': 87, 'n': 82, 'i': 78, 't': 77, 'r': 75, 'o': 73, 's': 63, 'h': 46, 'l': 44, 'd': 41, 'c': 41, 'f': 29, 'm': 28, 'u': 20, 'y': 18, 'p': 18, 'g': 16, 'w': 14, ',': 13, 'v': 12, 'b': 10, '.': 9, 'P': 4, 'E': 3, 'A': 2, 'â': 2, '€': 2, '™': 2, 'j': 2, '1': 2, '8': 2, '-': 2, 'I': 2, 'z': 2, 'T': 2, 'J': 1, 'B': 1, 'W': 1, 'M': 1, 'k': 1, 'x': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "the_count = Counter(x)\n",
    "print(the_count)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "322f2e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Office', 'of', 'Business', 'Economics', '(', ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.words(categories='government')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c253bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 16), ('and', 13), ('of', 8), ('social', 5)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "split_it = x.split()\n",
    "Counter = Counter(split_it)\n",
    "most_occur = Counter.most_common(4)\n",
    "print(most_occur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee0b6d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt') \n",
    "nltk.download('wordnet') \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "sentences= nltk.sent_tokenize(x)\n",
    "length= len(sentences)\n",
    "length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bd1ed45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wsj_0001.mrg', 'wsj_0002.mrg', 'wsj_0003.mrg', 'wsj_0004.mrg', 'wsj_0005.mrg', 'wsj_0006.mrg', 'wsj_0007.mrg', 'wsj_0008.mrg', 'wsj_0009.mrg', 'wsj_0010.mrg', 'wsj_0011.mrg', 'wsj_0012.mrg', 'wsj_0013.mrg', 'wsj_0014.mrg', 'wsj_0015.mrg', 'wsj_0016.mrg', 'wsj_0017.mrg', 'wsj_0018.mrg', 'wsj_0019.mrg', 'wsj_0020.mrg', 'wsj_0021.mrg', 'wsj_0022.mrg', 'wsj_0023.mrg', 'wsj_0024.mrg', 'wsj_0025.mrg', 'wsj_0026.mrg', 'wsj_0027.mrg', 'wsj_0028.mrg', 'wsj_0029.mrg', 'wsj_0030.mrg', 'wsj_0031.mrg', 'wsj_0032.mrg', 'wsj_0033.mrg', 'wsj_0034.mrg', 'wsj_0035.mrg', 'wsj_0036.mrg', 'wsj_0037.mrg', 'wsj_0038.mrg', 'wsj_0039.mrg', 'wsj_0040.mrg', 'wsj_0041.mrg', 'wsj_0042.mrg', 'wsj_0043.mrg', 'wsj_0044.mrg', 'wsj_0045.mrg', 'wsj_0046.mrg', 'wsj_0047.mrg', 'wsj_0048.mrg', 'wsj_0049.mrg', 'wsj_0050.mrg', 'wsj_0051.mrg', 'wsj_0052.mrg', 'wsj_0053.mrg', 'wsj_0054.mrg', 'wsj_0055.mrg', 'wsj_0056.mrg', 'wsj_0057.mrg', 'wsj_0058.mrg', 'wsj_0059.mrg', 'wsj_0060.mrg', 'wsj_0061.mrg', 'wsj_0062.mrg', 'wsj_0063.mrg', 'wsj_0064.mrg', 'wsj_0065.mrg', 'wsj_0066.mrg', 'wsj_0067.mrg', 'wsj_0068.mrg', 'wsj_0069.mrg', 'wsj_0070.mrg', 'wsj_0071.mrg', 'wsj_0072.mrg', 'wsj_0073.mrg', 'wsj_0074.mrg', 'wsj_0075.mrg', 'wsj_0076.mrg', 'wsj_0077.mrg', 'wsj_0078.mrg', 'wsj_0079.mrg', 'wsj_0080.mrg', 'wsj_0081.mrg', 'wsj_0082.mrg', 'wsj_0083.mrg', 'wsj_0084.mrg', 'wsj_0085.mrg', 'wsj_0086.mrg', 'wsj_0087.mrg', 'wsj_0088.mrg', 'wsj_0089.mrg', 'wsj_0090.mrg', 'wsj_0091.mrg', 'wsj_0092.mrg', 'wsj_0093.mrg', 'wsj_0094.mrg', 'wsj_0095.mrg', 'wsj_0096.mrg', 'wsj_0097.mrg', 'wsj_0098.mrg', 'wsj_0099.mrg', 'wsj_0100.mrg', 'wsj_0101.mrg', 'wsj_0102.mrg', 'wsj_0103.mrg', 'wsj_0104.mrg', 'wsj_0105.mrg', 'wsj_0106.mrg', 'wsj_0107.mrg', 'wsj_0108.mrg', 'wsj_0109.mrg', 'wsj_0110.mrg', 'wsj_0111.mrg', 'wsj_0112.mrg', 'wsj_0113.mrg', 'wsj_0114.mrg', 'wsj_0115.mrg', 'wsj_0116.mrg', 'wsj_0117.mrg', 'wsj_0118.mrg', 'wsj_0119.mrg', 'wsj_0120.mrg', 'wsj_0121.mrg', 'wsj_0122.mrg', 'wsj_0123.mrg', 'wsj_0124.mrg', 'wsj_0125.mrg', 'wsj_0126.mrg', 'wsj_0127.mrg', 'wsj_0128.mrg', 'wsj_0129.mrg', 'wsj_0130.mrg', 'wsj_0131.mrg', 'wsj_0132.mrg', 'wsj_0133.mrg', 'wsj_0134.mrg', 'wsj_0135.mrg', 'wsj_0136.mrg', 'wsj_0137.mrg', 'wsj_0138.mrg', 'wsj_0139.mrg', 'wsj_0140.mrg', 'wsj_0141.mrg', 'wsj_0142.mrg', 'wsj_0143.mrg', 'wsj_0144.mrg', 'wsj_0145.mrg', 'wsj_0146.mrg', 'wsj_0147.mrg', 'wsj_0148.mrg', 'wsj_0149.mrg', 'wsj_0150.mrg', 'wsj_0151.mrg', 'wsj_0152.mrg', 'wsj_0153.mrg', 'wsj_0154.mrg', 'wsj_0155.mrg', 'wsj_0156.mrg', 'wsj_0157.mrg', 'wsj_0158.mrg', 'wsj_0159.mrg', 'wsj_0160.mrg', 'wsj_0161.mrg', 'wsj_0162.mrg', 'wsj_0163.mrg', 'wsj_0164.mrg', 'wsj_0165.mrg', 'wsj_0166.mrg', 'wsj_0167.mrg', 'wsj_0168.mrg', 'wsj_0169.mrg', 'wsj_0170.mrg', 'wsj_0171.mrg', 'wsj_0172.mrg', 'wsj_0173.mrg', 'wsj_0174.mrg', 'wsj_0175.mrg', 'wsj_0176.mrg', 'wsj_0177.mrg', 'wsj_0178.mrg', 'wsj_0179.mrg', 'wsj_0180.mrg', 'wsj_0181.mrg', 'wsj_0182.mrg', 'wsj_0183.mrg', 'wsj_0184.mrg', 'wsj_0185.mrg', 'wsj_0186.mrg', 'wsj_0187.mrg', 'wsj_0188.mrg', 'wsj_0189.mrg', 'wsj_0190.mrg', 'wsj_0191.mrg', 'wsj_0192.mrg', 'wsj_0193.mrg', 'wsj_0194.mrg', 'wsj_0195.mrg', 'wsj_0196.mrg', 'wsj_0197.mrg', 'wsj_0198.mrg', 'wsj_0199.mrg']\n",
      "['A', 'form', 'of', 'asbestos', 'once', 'used', '*', ...]\n",
      "[('A', 'DT'), ('form', 'NN'), ('of', 'IN'), ...]\n",
      "(S\n",
      "  (S-TPC-1\n",
      "    (NP-SBJ\n",
      "      (NP (NP (DT A) (NN form)) (PP (IN of) (NP (NN asbestos))))\n",
      "      (RRC\n",
      "        (ADVP-TMP (RB once))\n",
      "        (VP\n",
      "          (VBN used)\n",
      "          (NP (-NONE- *))\n",
      "          (S-CLR\n",
      "            (NP-SBJ (-NONE- *))\n",
      "            (VP\n",
      "              (TO to)\n",
      "              (VP\n",
      "                (VB make)\n",
      "                (NP (NNP Kent) (NN cigarette) (NNS filters))))))))\n",
      "    (VP\n",
      "      (VBZ has)\n",
      "      (VP\n",
      "        (VBN caused)\n",
      "        (NP\n",
      "          (NP (DT a) (JJ high) (NN percentage))\n",
      "          (PP (IN of) (NP (NN cancer) (NNS deaths)))\n",
      "          (PP-LOC\n",
      "            (IN among)\n",
      "            (NP\n",
      "              (NP (DT a) (NN group))\n",
      "              (PP\n",
      "                (IN of)\n",
      "                (NP\n",
      "                  (NP (NNS workers))\n",
      "                  (RRC\n",
      "                    (VP\n",
      "                      (VBN exposed)\n",
      "                      (NP (-NONE- *))\n",
      "                      (PP-CLR (TO to) (NP (PRP it)))\n",
      "                      (ADVP-TMP\n",
      "                        (NP\n",
      "                          (QP (RBR more) (IN than) (CD 30))\n",
      "                          (NNS years))\n",
      "                        (IN ago))))))))))))\n",
      "  (, ,)\n",
      "  (NP-SBJ (NNS researchers))\n",
      "  (VP (VBD reported) (SBAR (-NONE- 0) (S (-NONE- *T*-1))))\n",
      "  (. .))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('treebank')\n",
    "from nltk.corpus import treebank\n",
    "print(treebank.fileids())\n",
    "print(treebank.words('wsj_0003.mrg'))\n",
    "print(treebank.tagged_words('wsj_0003.mrg'))\n",
    "print(treebank.parsed_sents('wsj_0003.mrg')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b78e25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]\n",
      "[('The', 'AT'), ('Fulton', 'NP-TL'), ...]\n",
      "[['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.'], ...]\n",
      "[[('The', 'AT'), ('Fulton', 'NP-TL'), ('County', 'NN-TL'), ('Grand', 'JJ-TL'), ('Jury', 'NN-TL'), ('said', 'VBD'), ('Friday', 'NR'), ('an', 'AT'), ('investigation', 'NN'), ('of', 'IN'), (\"Atlanta's\", 'NP$'), ('recent', 'JJ'), ('primary', 'NN'), ('election', 'NN'), ('produced', 'VBD'), ('``', '``'), ('no', 'AT'), ('evidence', 'NN'), (\"''\", \"''\"), ('that', 'CS'), ('any', 'DTI'), ('irregularities', 'NNS'), ('took', 'VBD'), ('place', 'NN'), ('.', '.')], [('The', 'AT'), ('jury', 'NN'), ('further', 'RBR'), ('said', 'VBD'), ('in', 'IN'), ('term-end', 'NN'), ('presentments', 'NNS'), ('that', 'CS'), ('the', 'AT'), ('City', 'NN-TL'), ('Executive', 'JJ-TL'), ('Committee', 'NN-TL'), (',', ','), ('which', 'WDT'), ('had', 'HVD'), ('over-all', 'JJ'), ('charge', 'NN'), ('of', 'IN'), ('the', 'AT'), ('election', 'NN'), (',', ','), ('``', '``'), ('deserves', 'VBZ'), ('the', 'AT'), ('praise', 'NN'), ('and', 'CC'), ('thanks', 'NNS'), ('of', 'IN'), ('the', 'AT'), ('City', 'NN-TL'), ('of', 'IN-TL'), ('Atlanta', 'NP-TL'), (\"''\", \"''\"), ('for', 'IN'), ('the', 'AT'), ('manner', 'NN'), ('in', 'IN'), ('which', 'WDT'), ('the', 'AT'), ('election', 'NN'), ('was', 'BEDZ'), ('conducted', 'VBN'), ('.', '.')], ...]\n",
      "[[['It', 'is', 'not', 'news', 'that', 'Nathan', 'Milstein', 'is', 'a', 'wizard', 'of', 'the', 'violin', '.'], ['Certainly', 'not', 'in', 'Orchestra', 'Hall', 'where', 'he', 'has', 'played', 'countless', 'recitals', ',', 'and', 'where', 'Thursday', 'night', 'he', 'celebrated', 'his', '20th', 'season', 'with', 'the', 'Chicago', 'Symphony', 'Orchestra', ',', 'playing', 'the', 'Brahms', 'Concerto', 'with', 'his', 'own', 'slashing', ',', 'demon-ridden', 'cadenza', 'melting', 'into', 'the', 'high', ',', 'pale', ',', 'pure', 'and', 'lovely', 'song', 'with', 'which', 'a', 'violinist', 'unlocks', 'the', 'heart', 'of', 'the', 'music', ',', 'or', 'forever', 'finds', 'it', 'closed', '.']], [['There', 'was', 'about', 'that', 'song', 'something', 'incandescent', ',', 'for', 'this', 'Brahms', 'was', 'Milstein', 'at', 'white', 'heat', '.'], ['Not', 'the', 'noblest', 'performance', 'we', 'have', 'heard', 'him', 'play', ',', 'or', 'the', 'most', 'spacious', ',', 'or', 'even', 'the', 'most', 'eloquent', '.'], ['Those', 'would', 'be', 'reserved', 'for', 'the', \"orchestra's\", 'great', 'nights', 'when', 'the', 'soloist', 'can', 'surpass', 'himself', '.'], ['This', 'time', 'the', 'orchestra', 'gave', 'him', 'some', 'superb', 'support', 'fired', 'by', 'response', 'to', 'his', 'own', 'high', 'mood', '.'], ['But', 'he', 'had', 'in', 'Walter', 'Hendl', 'a', 'willing', 'conductor', 'able', 'only', 'up', 'to', 'a', 'point', '.']], ...]\n",
      "[[[('It', 'PPS'), ('is', 'BEZ'), ('not', '*'), ('news', 'NN'), ('that', 'CS'), ('Nathan', 'NP'), ('Milstein', 'NP'), ('is', 'BEZ'), ('a', 'AT'), ('wizard', 'NN'), ('of', 'IN'), ('the', 'AT'), ('violin', 'NN'), ('.', '.')], [('Certainly', 'RB'), ('not', '*'), ('in', 'IN'), ('Orchestra', 'NN-TL'), ('Hall', 'NN-TL'), ('where', 'WRB'), ('he', 'PPS'), ('has', 'HVZ'), ('played', 'VBN'), ('countless', 'JJ'), ('recitals', 'NNS'), (',', ','), ('and', 'CC'), ('where', 'WRB'), ('Thursday', 'NR'), ('night', 'NN'), ('he', 'PPS'), ('celebrated', 'VBD'), ('his', 'PP$'), ('20th', 'OD'), ('season', 'NN'), ('with', 'IN'), ('the', 'AT'), ('Chicago', 'NP-TL'), ('Symphony', 'NN-TL'), ('Orchestra', 'NN-TL'), (',', ','), ('playing', 'VBG'), ('the', 'AT'), ('Brahms', 'NP-TL'), ('Concerto', 'NN-TL'), ('with', 'IN'), ('his', 'PP$'), ('own', 'JJ'), ('slashing', 'VBG'), (',', ','), ('demon-ridden', 'JJ'), ('cadenza', 'NN'), ('melting', 'VBG'), ('into', 'IN'), ('the', 'AT'), ('high', 'JJ'), (',', ','), ('pale', 'JJ'), (',', ','), ('pure', 'JJ'), ('and', 'CC'), ('lovely', 'JJ'), ('song', 'NN'), ('with', 'IN'), ('which', 'WDT'), ('a', 'AT'), ('violinist', 'NN'), ('unlocks', 'VBZ'), ('the', 'AT'), ('heart', 'NN'), ('of', 'IN'), ('the', 'AT'), ('music', 'NN'), (',', ','), ('or', 'CC'), ('forever', 'RB'), ('finds', 'VBZ'), ('it', 'PPO'), ('closed', 'VBN'), ('.', '.')]], [[('There', 'EX'), ('was', 'BEDZ'), ('about', 'IN'), ('that', 'DT'), ('song', 'NN'), ('something', 'PN'), ('incandescent', 'JJ'), (',', ','), ('for', 'CS'), ('this', 'DT'), ('Brahms', 'NP'), ('was', 'BEDZ'), ('Milstein', 'NP'), ('at', 'IN'), ('white', 'JJ'), ('heat', 'NN'), ('.', '.')], [('Not', '*'), ('the', 'AT'), ('noblest', 'JJT'), ('performance', 'NN'), ('we', 'PPSS'), ('have', 'HV'), ('heard', 'VBN'), ('him', 'PPO'), ('play', 'VB'), (',', ','), ('or', 'CC'), ('the', 'AT'), ('most', 'QL'), ('spacious', 'JJ'), (',', ','), ('or', 'CC'), ('even', 'RB'), ('the', 'AT'), ('most', 'QL'), ('eloquent', 'JJ'), ('.', '.')], [('Those', 'DTS'), ('would', 'MD'), ('be', 'BE'), ('reserved', 'VBN'), ('for', 'IN'), ('the', 'AT'), (\"orchestra's\", 'NN$'), ('great', 'JJ'), ('nights', 'NNS'), ('when', 'WRB'), ('the', 'AT'), ('soloist', 'NN'), ('can', 'MD'), ('surpass', 'VB'), ('himself', 'PPL'), ('.', '.')], [('This', 'DT'), ('time', 'NN'), ('the', 'AT'), ('orchestra', 'NN'), ('gave', 'VBD'), ('him', 'PPO'), ('some', 'DTI'), ('superb', 'JJ'), ('support', 'NN'), ('fired', 'VBN'), ('by', 'IN'), ('response', 'NN'), ('to', 'IN'), ('his', 'PP$'), ('own', 'JJ'), ('high', 'JJ'), ('mood', 'NN'), ('.', '.')], [('But', 'CC'), ('he', 'PPS'), ('had', 'HVD'), ('in', 'IN'), ('Walter', 'NP'), ('Hendl', 'NP'), ('a', 'AT'), ('willing', 'JJ'), ('conductor', 'NN'), ('able', 'JJ'), ('only', 'RB'), ('up', 'IN'), ('to', 'IN'), ('a', 'AT'), ('point', 'NN'), ('.', '.')]], ...]\n"
     ]
    }
   ],
   "source": [
    "#POS tagged corpora\n",
    "from nltk.corpus import brown\n",
    "print(brown.words())\n",
    "print(brown.tagged_words())\n",
    "print(brown.sents())\n",
    "print(brown.tagged_sents())\n",
    "print(brown.paras(categories='reviews'))\n",
    "print(brown.tagged_paras(categories='reviews'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62132821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['মহিষের', 'সন্তান', ':', 'তোড়া', 'উপজাতি', '৷', ...]\n",
      "[('মহিষের', 'NN'), ('সন্তান', 'NN'), (':', 'SYM'), ...]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package indian to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package indian is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('indian')\n",
    "from nltk.corpus import indian\n",
    "print(indian.words()) \n",
    "print(indian.tagged_words()) \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47a0ccc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('The', 'DET'), ('Fulton', 'NOUN'), ('County', 'NOUN'), ('Grand', 'ADJ'), ('Jury', 'NOUN'), ('said', 'VERB'), ('Friday', 'NOUN'), ('an', 'DET'), ('investigation', 'NOUN'), ('of', 'ADP'), (\"Atlanta's\", 'NOUN'), ('recent', 'ADJ'), ('primary', 'NOUN'), ('election', 'NOUN'), ('produced', 'VERB'), ('``', '.'), ('no', 'DET'), ('evidence', 'NOUN'), (\"''\", '.'), ('that', 'ADP'), ('any', 'DET'), ('irregularities', 'NOUN'), ('took', 'VERB'), ('place', 'NOUN'), ('.', '.')], [('The', 'DET'), ('jury', 'NOUN'), ('further', 'ADV'), ('said', 'VERB'), ('in', 'ADP'), ('term-end', 'NOUN'), ('presentments', 'NOUN'), ('that', 'ADP'), ('the', 'DET'), ('City', 'NOUN'), ('Executive', 'ADJ'), ('Committee', 'NOUN'), (',', '.'), ('which', 'DET'), ('had', 'VERB'), ('over-all', 'ADJ'), ('charge', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('election', 'NOUN'), (',', '.'), ('``', '.'), ('deserves', 'VERB'), ('the', 'DET'), ('praise', 'NOUN'), ('and', 'CONJ'), ('thanks', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('City', 'NOUN'), ('of', 'ADP'), ('Atlanta', 'NOUN'), (\"''\", '.'), ('for', 'ADP'), ('the', 'DET'), ('manner', 'NOUN'), ('in', 'ADP'), ('which', 'DET'), ('the', 'DET'), ('election', 'NOUN'), ('was', 'VERB'), ('conducted', 'VERB'), ('.', '.')], ...]\n",
      "[('Confidence', 'NOUN'), ('in', 'ADP'), ('the', 'DET'), ...]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package universal_tagset to C:\\Users\\Saumya\n",
      "[nltk_data]     Vikas Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n",
      "[nltk_data] Downloading package conll2000 to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package switchboard to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package switchboard is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('universal_tagset')\n",
    "nltk.download('conll2000')\n",
    "nltk.download('switchboard')\n",
    "print(brown.tagged_sents(tagset='universal'))\n",
    "from nltk.corpus import conll2000, switchboard\n",
    "print(conll2000.tagged_words(tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d39b03fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['jane austenâ€™s pride and prejudice is an 18th-century novel of manners set in rural england and portraying the relationships between the four daughters of the bennet family and their neighbors.',\n",
       " 'while accurately and vividly depicting the manners and social norms of that time, the novel also provides sharp observations on the themes of love, marriage, class, money, education, and social prestige.',\n",
       " 'in this paper, the four main themes of pride and prejudice are analyzed.',\n",
       " 'marriage is the main topic around which the plot revolves.',\n",
       " 'the author illustrates the conflict between marrying for money, which was the typical idea at the time, and marrying for love.',\n",
       " 'in either case, the economic and social differences were obstacles which made it hard for young women from poor families to break out of their social circle.',\n",
       " 'each personâ€™s position in society was determined by their class, and the relations between families also centered around differences in wealth and status.',\n",
       " 'the gender differences also played an important role, as women were considered inferior to men and were practically unable to choose partners.',\n",
       " 'austen both criticizes and examines the social life of 18th-century england, advocating for marrying for love as one of the essential female rights.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#3\n",
    "x = x.lower()\n",
    "     \n",
    "\n",
    "nltk.download('punkt') \n",
    "nltk.download('wordnet') \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "sent_tokens = nltk.sent_tokenize(x) \n",
    "word_tokens = nltk.word_tokenize(x) \n",
    "sent_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4ef6c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jane',\n",
       " 'austenâ€™s',\n",
       " 'pride',\n",
       " 'and',\n",
       " 'prejudice',\n",
       " 'is',\n",
       " 'an',\n",
       " '18th-century',\n",
       " 'novel',\n",
       " 'of',\n",
       " 'manners',\n",
       " 'set',\n",
       " 'in',\n",
       " 'rural',\n",
       " 'england',\n",
       " 'and',\n",
       " 'portraying',\n",
       " 'the',\n",
       " 'relationships',\n",
       " 'between',\n",
       " 'the',\n",
       " 'four',\n",
       " 'daughters',\n",
       " 'of',\n",
       " 'the',\n",
       " 'bennet',\n",
       " 'family',\n",
       " 'and',\n",
       " 'their',\n",
       " 'neighbors',\n",
       " '.',\n",
       " 'while',\n",
       " 'accurately',\n",
       " 'and',\n",
       " 'vividly',\n",
       " 'depicting',\n",
       " 'the',\n",
       " 'manners',\n",
       " 'and',\n",
       " 'social',\n",
       " 'norms',\n",
       " 'of',\n",
       " 'that',\n",
       " 'time',\n",
       " ',',\n",
       " 'the',\n",
       " 'novel',\n",
       " 'also',\n",
       " 'provides',\n",
       " 'sharp',\n",
       " 'observations',\n",
       " 'on',\n",
       " 'the',\n",
       " 'themes',\n",
       " 'of',\n",
       " 'love',\n",
       " ',',\n",
       " 'marriage',\n",
       " ',',\n",
       " 'class',\n",
       " ',',\n",
       " 'money',\n",
       " ',',\n",
       " 'education',\n",
       " ',',\n",
       " 'and',\n",
       " 'social',\n",
       " 'prestige',\n",
       " '.',\n",
       " 'in',\n",
       " 'this',\n",
       " 'paper',\n",
       " ',',\n",
       " 'the',\n",
       " 'four',\n",
       " 'main',\n",
       " 'themes',\n",
       " 'of',\n",
       " 'pride',\n",
       " 'and',\n",
       " 'prejudice',\n",
       " 'are',\n",
       " 'analyzed',\n",
       " '.',\n",
       " 'marriage',\n",
       " 'is',\n",
       " 'the',\n",
       " 'main',\n",
       " 'topic',\n",
       " 'around',\n",
       " 'which',\n",
       " 'the',\n",
       " 'plot',\n",
       " 'revolves',\n",
       " '.',\n",
       " 'the',\n",
       " 'author',\n",
       " 'illustrates',\n",
       " 'the',\n",
       " 'conflict',\n",
       " 'between',\n",
       " 'marrying',\n",
       " 'for',\n",
       " 'money',\n",
       " ',',\n",
       " 'which',\n",
       " 'was',\n",
       " 'the',\n",
       " 'typical',\n",
       " 'idea',\n",
       " 'at',\n",
       " 'the',\n",
       " 'time',\n",
       " ',',\n",
       " 'and',\n",
       " 'marrying',\n",
       " 'for',\n",
       " 'love',\n",
       " '.',\n",
       " 'in',\n",
       " 'either',\n",
       " 'case',\n",
       " ',',\n",
       " 'the',\n",
       " 'economic',\n",
       " 'and',\n",
       " 'social',\n",
       " 'differences',\n",
       " 'were',\n",
       " 'obstacles',\n",
       " 'which',\n",
       " 'made',\n",
       " 'it',\n",
       " 'hard',\n",
       " 'for',\n",
       " 'young',\n",
       " 'women',\n",
       " 'from',\n",
       " 'poor',\n",
       " 'families',\n",
       " 'to',\n",
       " 'break',\n",
       " 'out',\n",
       " 'of',\n",
       " 'their',\n",
       " 'social',\n",
       " 'circle',\n",
       " '.',\n",
       " 'each',\n",
       " 'personâ€™s',\n",
       " 'position',\n",
       " 'in',\n",
       " 'society',\n",
       " 'was',\n",
       " 'determined',\n",
       " 'by',\n",
       " 'their',\n",
       " 'class',\n",
       " ',',\n",
       " 'and',\n",
       " 'the',\n",
       " 'relations',\n",
       " 'between',\n",
       " 'families',\n",
       " 'also',\n",
       " 'centered',\n",
       " 'around',\n",
       " 'differences',\n",
       " 'in',\n",
       " 'wealth',\n",
       " 'and',\n",
       " 'status',\n",
       " '.',\n",
       " 'the',\n",
       " 'gender',\n",
       " 'differences',\n",
       " 'also',\n",
       " 'played',\n",
       " 'an',\n",
       " 'important',\n",
       " 'role',\n",
       " ',',\n",
       " 'as',\n",
       " 'women',\n",
       " 'were',\n",
       " 'considered',\n",
       " 'inferior',\n",
       " 'to',\n",
       " 'men',\n",
       " 'and',\n",
       " 'were',\n",
       " 'practically',\n",
       " 'unable',\n",
       " 'to',\n",
       " 'choose',\n",
       " 'partners',\n",
       " '.',\n",
       " 'austen',\n",
       " 'both',\n",
       " 'criticizes',\n",
       " 'and',\n",
       " 'examines',\n",
       " 'the',\n",
       " 'social',\n",
       " 'life',\n",
       " 'of',\n",
       " '18th-century',\n",
       " 'england',\n",
       " ',',\n",
       " 'advocating',\n",
       " 'for',\n",
       " 'marrying',\n",
       " 'for',\n",
       " 'love',\n",
       " 'as',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'essential',\n",
       " 'female',\n",
       " 'rights',\n",
       " '.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "731a752c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jane austenâ€™s pride prejudice 18th-century novel manners set rural england portraying relationships four daughters bennet family neighbors . accurately vividly depicting manners social norms time , novel also provides sharp observations themes love , marriage , class , money , education , social prestige . paper , four main themes pride prejudice analyzed . marriage main topic around plot revolves . author illustrates conflict marrying money , typical idea time , marrying love . either case , economic social differences obstacles made hard young women poor families break social circle . personâ€™s position society determined class , relations families also centered around differences wealth status . gender differences also played important role , women considered inferior men practically unable choose partners . austen criticizes examines social life 18th-century england , advocating marrying love one essential female rights .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(x)\n",
    "filtered_text = [t for t in tokens if not t in stopwords.words(\"english\")]\n",
    "print(\" \".join(filtered_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "459f025e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jane', 'austenâ€™s', 'pride', 'and', 'prejudice', 'is', 'an', '18th-century', 'novel', 'of', 'manners', 'set', 'in', 'rural', 'england', 'and', 'portraying', 'the', 'relationships', 'between', 'the', 'four', 'daughters', 'of', 'the', 'bennet', 'family', 'and', 'their', 'neighbors', '.', 'while', 'accurately', 'and', 'vividly', 'depicting', 'the', 'manners', 'and', 'social', 'norms', 'of', 'that', 'time', ',', 'the', 'novel', 'also', 'provides', 'sharp', 'observations', 'on', 'the', 'themes', 'of', 'love', ',', 'marriage', ',', 'class', ',', 'money', ',', 'education', ',', 'and', 'social', 'prestige', '.', 'in', 'this', 'paper', ',', 'the', 'four', 'main', 'themes', 'of', 'pride', 'and', 'prejudice', 'are', 'analyzed', '.', 'marriage', 'is', 'the', 'main', 'topic', 'around', 'which', 'the', 'plot', 'revolves', '.', 'the', 'author', 'illustrates', 'the', 'conflict', 'between', 'marrying', 'for', 'money', ',', 'which', 'was', 'the', 'typical', 'idea', 'at', 'the', 'time', ',', 'and', 'marrying', 'for', 'love', '.', 'in', 'either', 'case', ',', 'the', 'economic', 'and', 'social', 'differences', 'were', 'obstacles', 'which', 'made', 'it', 'hard', 'for', 'young', 'women', 'from', 'poor', 'families', 'to', 'break', 'out', 'of', 'their', 'social', 'circle', '.', 'each', 'personâ€™s', 'position', 'in', 'society', 'was', 'determined', 'by', 'their', 'class', ',', 'and', 'the', 'relations', 'between', 'families', 'also', 'centered', 'around', 'differences', 'in', 'wealth', 'and', 'status', '.', 'the', 'gender', 'differences', 'also', 'played', 'an', 'important', 'role', ',', 'as', 'women', 'were', 'considered', 'inferior', 'to', 'men', 'and', 'were', 'practically', 'unable', 'to', 'choose', 'partners', '.', 'austen', 'both', 'criticizes', 'and', 'examines', 'the', 'social', 'life', 'of', '18th-century', 'england', ',', 'advocating', 'for', 'marrying', 'for', 'love', 'as', 'one', 'of', 'the', 'essential', 'female', 'rights', '.']\n",
      "['jane', 'austenâ€™', 'pride', 'and', 'prejudic', 'is', 'an', '18th-centuri', 'novel', 'of', 'manner', 'set', 'in', 'rural', 'england', 'and', 'portray', 'the', 'relationship', 'between', 'the', 'four', 'daughter', 'of', 'the', 'bennet', 'famili', 'and', 'their', 'neighbor', '.', 'while', 'accur', 'and', 'vividli', 'depict', 'the', 'manner', 'and', 'social', 'norm', 'of', 'that', 'time', ',', 'the', 'novel', 'also', 'provid', 'sharp', 'observ', 'on', 'the', 'theme', 'of', 'love', ',', 'marriag', ',', 'class', ',', 'money', ',', 'educ', ',', 'and', 'social', 'prestig', '.', 'in', 'thi', 'paper', ',', 'the', 'four', 'main', 'theme', 'of', 'pride', 'and', 'prejudic', 'are', 'analyz', '.', 'marriag', 'is', 'the', 'main', 'topic', 'around', 'which', 'the', 'plot', 'revolv', '.', 'the', 'author', 'illustr', 'the', 'conflict', 'between', 'marri', 'for', 'money', ',', 'which', 'wa', 'the', 'typic', 'idea', 'at', 'the', 'time', ',', 'and', 'marri', 'for', 'love', '.', 'in', 'either', 'case', ',', 'the', 'econom', 'and', 'social', 'differ', 'were', 'obstacl', 'which', 'made', 'it', 'hard', 'for', 'young', 'women', 'from', 'poor', 'famili', 'to', 'break', 'out', 'of', 'their', 'social', 'circl', '.', 'each', 'personâ€™', 'posit', 'in', 'societi', 'wa', 'determin', 'by', 'their', 'class', ',', 'and', 'the', 'relat', 'between', 'famili', 'also', 'center', 'around', 'differ', 'in', 'wealth', 'and', 'statu', '.', 'the', 'gender', 'differ', 'also', 'play', 'an', 'import', 'role', ',', 'as', 'women', 'were', 'consid', 'inferior', 'to', 'men', 'and', 'were', 'practic', 'unabl', 'to', 'choos', 'partner', '.', 'austen', 'both', 'critic', 'and', 'examin', 'the', 'social', 'life', 'of', '18th-centuri', 'england', ',', 'advoc', 'for', 'marri', 'for', 'love', 'as', 'one', 'of', 'the', 'essenti', 'femal', 'right', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd \n",
    "ps = PorterStemmer()\n",
    "tokens = word_tokenize(x)\n",
    "print(tokens)\n",
    "stemmed = []\n",
    "for token in tokens:\n",
    "     stemmed_word = ps.stem(token)\n",
    "     stemmed.append(stemmed_word)\n",
    "print(stemmed)\n",
    "df = pd.DataFrame(data={\"tokens\":tokens, \"stemmed\": stemmed})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "22d61293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                Lemma               \n",
      "jane                jane                \n",
      "austenâ€™s          austenâ€™s          \n",
      "pride               pride               \n",
      "and                 and                 \n",
      "prejudice           prejudice           \n",
      "is                  is                  \n",
      "an                  an                  \n",
      "18th-century        18th-century        \n",
      "novel               novel               \n",
      "of                  of                  \n",
      "manners             manner              \n",
      "set                 set                 \n",
      "in                  in                  \n",
      "rural               rural               \n",
      "england             england             \n",
      "and                 and                 \n",
      "portraying          portraying          \n",
      "the                 the                 \n",
      "relationships       relationship        \n",
      "between             between             \n",
      "the                 the                 \n",
      "four                four                \n",
      "daughters           daughter            \n",
      "of                  of                  \n",
      "the                 the                 \n",
      "bennet              bennet              \n",
      "family              family              \n",
      "and                 and                 \n",
      "their               their               \n",
      "neighbors           neighbor            \n",
      "while               while               \n",
      "accurately          accurately          \n",
      "and                 and                 \n",
      "vividly             vividly             \n",
      "depicting           depicting           \n",
      "the                 the                 \n",
      "manners             manner              \n",
      "and                 and                 \n",
      "social              social              \n",
      "norms               norm                \n",
      "of                  of                  \n",
      "that                that                \n",
      "time                time                \n",
      "the                 the                 \n",
      "novel               novel               \n",
      "also                also                \n",
      "provides            provides            \n",
      "sharp               sharp               \n",
      "observations        observation         \n",
      "on                  on                  \n",
      "the                 the                 \n",
      "themes              theme               \n",
      "of                  of                  \n",
      "love                love                \n",
      "marriage            marriage            \n",
      "class               class               \n",
      "money               money               \n",
      "education           education           \n",
      "and                 and                 \n",
      "social              social              \n",
      "prestige            prestige            \n",
      "in                  in                  \n",
      "this                this                \n",
      "paper               paper               \n",
      "the                 the                 \n",
      "four                four                \n",
      "main                main                \n",
      "themes              theme               \n",
      "of                  of                  \n",
      "pride               pride               \n",
      "and                 and                 \n",
      "prejudice           prejudice           \n",
      "are                 are                 \n",
      "analyzed            analyzed            \n",
      "marriage            marriage            \n",
      "is                  is                  \n",
      "the                 the                 \n",
      "main                main                \n",
      "topic               topic               \n",
      "around              around              \n",
      "which               which               \n",
      "the                 the                 \n",
      "plot                plot                \n",
      "revolves            revolves            \n",
      "the                 the                 \n",
      "author              author              \n",
      "illustrates         illustrates         \n",
      "the                 the                 \n",
      "conflict            conflict            \n",
      "between             between             \n",
      "marrying            marrying            \n",
      "for                 for                 \n",
      "money               money               \n",
      "which               which               \n",
      "was                 wa                  \n",
      "the                 the                 \n",
      "typical             typical             \n",
      "idea                idea                \n",
      "at                  at                  \n",
      "the                 the                 \n",
      "time                time                \n",
      "and                 and                 \n",
      "marrying            marrying            \n",
      "for                 for                 \n",
      "love                love                \n",
      "in                  in                  \n",
      "either              either              \n",
      "case                case                \n",
      "the                 the                 \n",
      "economic            economic            \n",
      "and                 and                 \n",
      "social              social              \n",
      "differences         difference          \n",
      "were                were                \n",
      "obstacles           obstacle            \n",
      "which               which               \n",
      "made                made                \n",
      "it                  it                  \n",
      "hard                hard                \n",
      "for                 for                 \n",
      "young               young               \n",
      "women               woman               \n",
      "from                from                \n",
      "poor                poor                \n",
      "families            family              \n",
      "to                  to                  \n",
      "break               break               \n",
      "out                 out                 \n",
      "of                  of                  \n",
      "their               their               \n",
      "social              social              \n",
      "circle              circle              \n",
      "each                each                \n",
      "personâ€™s          personâ€™s          \n",
      "position            position            \n",
      "in                  in                  \n",
      "society             society             \n",
      "was                 wa                  \n",
      "determined          determined          \n",
      "by                  by                  \n",
      "their               their               \n",
      "class               class               \n",
      "and                 and                 \n",
      "the                 the                 \n",
      "relations           relation            \n",
      "between             between             \n",
      "families            family              \n",
      "also                also                \n",
      "centered            centered            \n",
      "around              around              \n",
      "differences         difference          \n",
      "in                  in                  \n",
      "wealth              wealth              \n",
      "and                 and                 \n",
      "status              status              \n",
      "the                 the                 \n",
      "gender              gender              \n",
      "differences         difference          \n",
      "also                also                \n",
      "played              played              \n",
      "an                  an                  \n",
      "important           important           \n",
      "role                role                \n",
      "as                  a                   \n",
      "women               woman               \n",
      "were                were                \n",
      "considered          considered          \n",
      "inferior            inferior            \n",
      "to                  to                  \n",
      "men                 men                 \n",
      "and                 and                 \n",
      "were                were                \n",
      "practically         practically         \n",
      "unable              unable              \n",
      "to                  to                  \n",
      "choose              choose              \n",
      "partners            partner             \n",
      "austen              austen              \n",
      "both                both                \n",
      "criticizes          criticizes          \n",
      "and                 and                 \n",
      "examines            examines            \n",
      "the                 the                 \n",
      "social              social              \n",
      "life                life                \n",
      "of                  of                  \n",
      "18th-century        18th-century        \n",
      "england             england             \n",
      "advocating          advocating          \n",
      "for                 for                 \n",
      "marrying            marrying            \n",
      "for                 for                 \n",
      "love                love                \n",
      "as                  a                   \n",
      "one                 one                 \n",
      "of                  of                  \n",
      "the                 the                 \n",
      "essential           essential           \n",
      "female              female              \n",
      "rights              right               \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Saumya Vikas\n",
      "[nltk_data]     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "punctuations=\"?:!.,;\"\n",
    "sentence_words = nltk.word_tokenize(x)\n",
    "for word in sentence_words:\n",
    "    if word in punctuations:\n",
    "        sentence_words.remove(word)\n",
    "\n",
    "sentence_words\n",
    "print(\"{0:20}{1:20}\".format(\"Word\",\"Lemma\"))\n",
    "for word in sentence_words:\n",
    "    print (\"{0:20}{1:20}\".format(word,wordnet_lemmatizer.lemmatize(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a1a1063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('jane', 'NN'), ('austenâ€™s', 'NNS'), ('pride', 'JJ'), ('prejudice', 'JJ'), ('18th-century', 'JJ'), ('novel', 'NN'), ('manners', 'NNS'), ('set', 'VBD'), ('rural', 'JJ'), ('england', 'NN'), ('portraying', 'VBG'), ('relationships', 'NNS'), ('four', 'CD'), ('daughters', 'NNS'), ('bennet', 'VBP'), ('family', 'NN'), ('neighbors', 'NNS'), ('.', '.')]\n",
      "[('accurately', 'RB'), ('vividly', 'RB'), ('depicting', 'VBG'), ('manners', 'NNS'), ('social', 'JJ'), ('norms', 'NNS'), ('time', 'NN'), (',', ','), ('novel', 'NN'), ('also', 'RB'), ('provides', 'VBZ'), ('sharp', 'JJ'), ('observations', 'NNS'), ('themes', 'NNS'), ('love', 'VBP'), (',', ','), ('marriage', 'NN'), (',', ','), ('class', 'NN'), (',', ','), ('money', 'NN'), (',', ','), ('education', 'NN'), (',', ','), ('social', 'JJ'), ('prestige', 'NN'), ('.', '.')]\n",
      "[('paper', 'NN'), (',', ','), ('four', 'CD'), ('main', 'JJ'), ('themes', 'NNS'), ('pride', 'JJ'), ('prejudice', 'NN'), ('analyzed', 'VBD'), ('.', '.')]\n",
      "[('marriage', 'NN'), ('main', 'JJ'), ('topic', 'NN'), ('around', 'IN'), ('plot', 'NN'), ('revolves', 'NNS'), ('.', '.')]\n",
      "[('author', 'NN'), ('illustrates', 'VBZ'), ('conflict', 'VBP'), ('marrying', 'VBG'), ('money', 'NN'), (',', ','), ('typical', 'JJ'), ('idea', 'NN'), ('time', 'NN'), (',', ','), ('marrying', 'VBG'), ('love', 'NN'), ('.', '.')]\n",
      "[('either', 'DT'), ('case', 'NN'), (',', ','), ('economic', 'JJ'), ('social', 'JJ'), ('differences', 'NNS'), ('obstacles', 'NNS'), ('made', 'VBN'), ('hard', 'JJ'), ('young', 'JJ'), ('women', 'NNS'), ('poor', 'JJ'), ('families', 'NNS'), ('break', 'VBP'), ('social', 'JJ'), ('circle', 'NN'), ('.', '.')]\n",
      "[('personâ€™s', 'JJ'), ('position', 'NN'), ('society', 'NN'), ('determined', 'VBD'), ('class', 'NN'), (',', ','), ('relations', 'NNS'), ('families', 'NNS'), ('also', 'RB'), ('centered', 'VBD'), ('around', 'IN'), ('differences', 'NNS'), ('wealth', 'NN'), ('status', 'NN'), ('.', '.')]\n",
      "[('gender', 'NN'), ('differences', 'NNS'), ('also', 'RB'), ('played', 'VBD'), ('important', 'JJ'), ('role', 'NN'), (',', ','), ('women', 'NNS'), ('considered', 'VBD'), ('inferior', 'JJ'), ('men', 'NNS'), ('practically', 'RB'), ('unable', 'JJ'), ('choose', 'JJ'), ('partners', 'NNS'), ('.', '.')]\n",
      "[('austen', 'RB'), ('criticizes', 'VBZ'), ('examines', 'NNS'), ('social', 'JJ'), ('life', 'NN'), ('18th-century', 'JJ'), ('england', 'NN'), (',', ','), ('advocating', 'VBG'), ('marrying', 'VBG'), ('love', 'VB'), ('one', 'CD'), ('essential', 'JJ'), ('female', 'NN'), ('rights', 'NNS'), ('.', '.')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Saumya Vikas\n",
      "[nltk_data]     Goel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokenized = sent_tokenize(x)\n",
    "for i in tokenized:\n",
    "\twordsList = nltk.word_tokenize(i)\n",
    "\twordsList = [w for w in wordsList if not w in stop_words]\n",
    "\ttagged = nltk.pos_tag(wordsList)\n",
    "\tprint(tagged)\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaaf9b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
